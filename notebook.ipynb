{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dad26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92849160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'input', 'output'],\n",
      "        num_rows: 112165\n",
      "    })\n",
      "})\n",
      "{'instruction': \"If you are a doctor, please answer the medical questions based on the patient's description.\", 'input': 'I woke up this morning feeling the whole room is spinning when i was sitting down. I went to the bathroom walking unsteadily, as i tried to focus i feel nauseous. I try to vomit but it wont come out.. After taking panadol and sleep for few hours, i still feel the same.. By the way, if i lay down or sit down, my head do not spin, only when i want to move around then i feel the whole world is spinning.. And it is normal stomach discomfort at the same time? Earlier after i relieved myself, the spinning lessen so i am not sure whether its connected or coincidences.. Thank you doc!', 'output': 'Hi, Thank you for posting your query. The most likely cause for your symptoms is benign paroxysmal positional vertigo (BPPV), a type of peripheral vertigo. In this condition, the most common symptom is dizziness or giddiness, which is made worse with movements. Accompanying nausea and vomiting are common. The condition is due to problem in the ear, and improves in a few days on own. Betahistine tablets would help relieve your symptoms. Doing vestibular rehabilitation or adaptation exercises would prevent the recurrence of these symptoms. An ENT evaluation would also help. I hope it helps. Best wishes, Chat Doctor.'}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "ds = load_dataset(\"lavita/ChatDoctor-HealthCareMagic-100k\")\n",
    "\n",
    "# Check structure\n",
    "print(ds)\n",
    "print(ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c112135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 112165/112165 [04:27<00:00, 419.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess(examples):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    attention_masks = []\n",
    "    for i in range(len(examples['input'])):\n",
    "      input_text = \"question: \" + examples['input'][i]\n",
    "      target_text = examples['output'][i]\n",
    "      tokenized_input = tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "      tokenized_label = tokenizer(target_text, padding=\"max_length\", truncation=True, max_length=128)\n",
    "      inputs.append(tokenized_input['input_ids'])\n",
    "      attention_masks.append(tokenized_input['attention_mask'])\n",
    "      labels.append(tokenized_label['input_ids'])\n",
    "    return {'input_ids': inputs, 'attention_mask': attention_masks, 'labels': labels}\n",
    "\n",
    "tokenized_ds = ds[\"train\"].map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aa02ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "Map: 100%|██████████| 10000/10000 [00:10<00:00, 968.87 examples/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Hp\\Documents\\Doctor_chatbox\\venv\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1250/1250 [==============================] - 8845s 7s/step - loss: 1.3140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x12ee2e1b620>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name, use_safetensors=False)\n",
    "\n",
    "train_dataset = tokenized_ds.shuffle(seed=42).select(range(10000)) \n",
    "\n",
    "def prepare_decoder_inputs(examples):\n",
    "    decoder_input_ids = np.array(examples[\"labels\"])[:, :-1].tolist()\n",
    "    # Pad decoder_input_ids to the same length as labels\n",
    "    padded_decoder_input_ids = [ids + [tokenizer.pad_token_id] * (128 - len(ids)) for ids in decoder_input_ids]\n",
    "    examples[\"decoder_input_ids\"] = padded_decoder_input_ids\n",
    "    return examples\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_decoder_inputs, batched=True)\n",
    "\n",
    "\n",
    "tf_dataset = train_dataset.to_tf_dataset(\n",
    "    columns=['input_ids', 'attention_mask', 'decoder_input_ids'],\n",
    "    label_cols=['labels'],\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "# Use ignore_index to exclude padding tokens from loss calculation\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "model.fit(tf_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e34cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save and test the model\n",
    "model.save_pretrained(\"healthcare_chatbot_model\")\n",
    "tokenizer.save_pretrained(\"healthcare_chatbot_model\")\n",
    "\n",
    "# Test response\n",
    "input_text = \"question: I have a sore throat and cough, what should I do?\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"tf\")\n",
    "output = model.generate(**inputs, max_length=50)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
